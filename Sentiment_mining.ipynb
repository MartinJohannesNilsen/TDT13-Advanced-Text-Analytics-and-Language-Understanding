{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jdg7OnonX0wf",
        "outputId": "144b0413-5ecc-41c6-c1fe-0c5c36a60102"
      },
      "outputs": [],
      "source": [
        "%pip install -r \"requirements.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DVIvNJcNX0wh",
        "outputId": "f433773a-7a35-4a54-9bd8-618a1e688b45"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "plt.style.use('ggplot')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "bdehiwDcX0wi",
        "outputId": "3805f68a-53aa-4b6d-c60b-28aeaea19fc5"
      },
      "outputs": [],
      "source": [
        "RAW_DATA = \"C:/Users/Jonas/ntnu_5/tdt13_nlp/aclImdb/dataset_raw\"\n",
        "SENTIMENT_DATA = \"C:/Users/Jonas/ntnu_5/tdt13_nlp/aclImdb/dataset_sentiment\"\n",
        "\n",
        "train_df = pd.read_csv(f\"{RAW_DATA}/train.csv\", delimiter=\"█\")\n",
        "test_df = pd.read_csv(f\"{RAW_DATA}/test.csv\", delimiter=\"█\")\n",
        "val_df = pd.read_csv(f\"{RAW_DATA}/validation.csv\", delimiter=\"█\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "l4jmnOc8X0ww"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from scipy.special import softmax\n",
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "66R-Y0agX0ww"
      },
      "outputs": [],
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "MODEL = f\"cardiffnlp/twitter-roberta-base-sentiment\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import re\n",
        "# Preprocess data\n",
        "def preprocess_function(text):\n",
        "\n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    # Replace '&amp;' with '&'\n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    # Remove trailing whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    # Remove html tags\n",
        "    text = re.sub('<[^<]+?>', '', text)\n",
        "    \n",
        "    # Change this to real number\n",
        "    #text[\"label\"] = float(label)\n",
        "    return text\n",
        "\n",
        "train_df[\"text\"] = train_df[\"text\"].apply(preprocess_function)\n",
        "test_df[\"text\"] = test_df[\"text\"].apply(preprocess_function)\n",
        "val_df[\"text\"] = val_df[\"text\"].apply(preprocess_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "SHtdQJeuX0wx"
      },
      "outputs": [],
      "source": [
        "def polarity_scores_roberta(example):\n",
        "    encoded_text = tokenizer(example, truncation=True, return_tensors=\"pt\", max_length=512).to(device)\n",
        "    output = model(**encoded_text)\n",
        "    scores = output[0][0].cpu().detach().numpy()\n",
        "    scores = softmax(scores)\n",
        "    scores_dict = {\n",
        "        \"roberta_neg\": scores[0],\n",
        "        \"roberta_neu\": scores[1],\n",
        "        \"roberta_pos\": scores[2],\n",
        "    }\n",
        "    return scores_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85pz5iLRX0wx"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def polarity_score_dataset(df):\n",
        "    res = {}\n",
        "    for i, row in tqdm(df.iterrows(), total=len(df.index)):\n",
        "        try:\n",
        "            text = row[\"text\"]\n",
        "            text_id = row[\"id\"]\n",
        "            res[text_id] = polarity_scores_roberta(text)\n",
        "        except RuntimeError:\n",
        "            print(f\"[ERROR] Broke for id {text_id}\")\n",
        "\n",
        "    return res\n",
        "\n",
        "train_polarity = polarity_score_dataset(train_df)\n",
        "test_polarity = polarity_score_dataset(test_df)\n",
        "val_polarity = polarity_score_dataset(val_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_polarity_df = pd.DataFrame.from_dict(train_polarity).T\n",
        "test_polarity_df = pd.DataFrame.from_dict(test_polarity).T\n",
        "val_polarity_df = pd.DataFrame.from_dict(val_polarity).T\n",
        "\n",
        "print(len(train_polarity_df.index))\n",
        "print(len(test_polarity_df.index))\n",
        "print(len(val_polarity_df.index))\n",
        "\n",
        "train_labels = pd.DataFrame(train_df[\"labels\"]).set_index(train_df[\"id\"])\n",
        "test_labels = pd.DataFrame(test_df[\"labels\"]).set_index(test_df[\"id\"])\n",
        "val_labels = pd.DataFrame(val_df[\"labels\"]).set_index(val_df[\"id\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "merged_train = pd.concat([train_labels, train_polarity_df], axis=1)\n",
        "merged_test = pd.concat([test_labels, test_polarity_df], axis=1)\n",
        "merged_val = pd.concat([val_labels, val_polarity_df], axis=1)\n",
        "\n",
        "merged_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "LmKGS7XBIvMw"
      },
      "outputs": [],
      "source": [
        "merged_train.to_csv(f\"{SENTIMENT_DATA}/train.csv\", sep=\"█\")\n",
        "merged_test.to_csv(f\"{SENTIMENT_DATA}/test.csv\", sep=\"█\")\n",
        "merged_val.to_csv(f\"{SENTIMENT_DATA}/validation.csv\", sep=\"█\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "aT2MOmg7X0wt",
        "zkMsyFPiX0wu",
        "HB4MknOUX0wy",
        "ZWUHwk6rX0wy"
      ],
      "provenance": []
    },
    "deepnote": {},
    "deepnote_execution_queue": [],
    "deepnote_notebook_id": "9882523760874feda0cbf51dd4751f2d",
    "deepnote_persisted_session": {
      "createdAt": "2022-11-13T14:24:44.927Z"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.10 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "vscode": {
      "interpreter": {
        "hash": "4c56407a4538f024563cd72c1bb5a8f6725b4567c8c6c37eefa2c8c05e49cfd2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
